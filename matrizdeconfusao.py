# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B5Ehq6tnwyo7vi4QpjFq96XotcNI50DV
"""

!pip install kaggle

!mkdir ~/.kaggle
!cp /content/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d d4rklucif3r/cat-and-dogs


!unzip /content/cat-and-dogs.zip

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Definindo os caminhos para os diretórios de treino e teste
train_dir = '/content/dataset/training_set'
test_dir = '/content/dataset/test_set'

# Criando os geradores de dados para aumentar os dados e carregar as imagens em batches
train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary')

# Criando o modelo sequencial
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(512, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compilando o modelo
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

# Treinando o modelo
history = model.fit(
      train_generator,
      epochs=10,
      validation_data=validation_generator)

# Salvando o modelo
model.save('cats_and_dogs_model.h5')

import numpy as np
import tensorflow as tf
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Carregar o modelo treinado
model = tf.keras.models.load_model('cats_and_dogs_model.h5')

# Gerador de validação
test_dir = '/content/dataset/test_set'
test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

validation_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary',
        shuffle=False)  # Importante não embaralhar as imagens para calcular corretamente a confusão

# Obter o número total de amostras
total_samples = validation_generator.samples

# Obter as previsões
steps = int(np.ceil(total_samples / validation_generator.batch_size))  # Converter para inteiro
predictions = model.predict(validation_generator, steps=steps)

# Converter as probabilidades para rótulos binários (0 ou 1)
predictions = np.round(predictions).astype(int)

# Obter as classes verdadeiras
true_classes = validation_generator.classes

# Gerar a matriz de confusão
cm = confusion_matrix(true_classes, predictions)

# Plotando a matriz de confusão
plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=validation_generator.class_indices.keys(), yticklabels=validation_generator.class_indices.keys())
plt.ylabel('Classe Real')
plt.xlabel('Classe Predita')
plt.title('Matriz de Confusão')
plt.show()

# Extraindo os valores da matriz de confusão
VP = cm[1, 1]  # Verdadeiros Positivos
FP = cm[0, 1]  # Falsos Positivos
FN = cm[1, 0]  # Falsos Negativos
VN = cm[0, 0]  # Verdadeiros Negativos

# Cálculo das métricas

# Acurácia
acuracia = (VP + VN) / (VP + FP + FN + VN)

# Sensibilidade (Recall)
sensibilidade = VP / (VP + FN)

# Especificidade
especificidade = VN / (VN + FP)

# Precisão
precisao = VP / (VP + FP)

# F1-Score
f1_score = 2 * (precisao * sensibilidade) / (precisao + sensibilidade)

# Exibindo os resultados
print(f"\nAcurácia: {acuracia:.4f}")
print(f"Sensibilidade (Recall): {sensibilidade:.4f}")
print(f"Especificidade: {especificidade:.4f}")
print(f"Precisão: {precisao:.4f}")
print(f"F1-Score: {f1_score:.4f}")